# Required_Final_Assignment_20.1-Introduction_to_Machine_Learning_and_Advanced_Probability_starter
Two comprehensive Jupyter notebooks  for Machine Learning and Advanced Probability
### Advanced Probability & Statistical Modeling (MIT xPro Final Assignment 20.1)
- **Notebook:** [GradientDesc_student.ipynb](https://github.com/MacAries1/Required_Final_Assignment_20.1-Introduction_to_Machine_Learning_and_Advanced_Probability_starter/blob/main/GradientDesc_student.ipynb)
- **Focus:** Probabilistic reasoning, gradient descent, and statistical modeling from first principles.
- **Highlights:**
  - Implemented gradient descent manually to optimize a cost function
  - Explored convergence behavior and learning rate sensitivity
  - Applied conditional probability and Bayesâ€™ theorem to real-world scenarios
  - Visualized parameter updates and loss curves for interpretability
- **Impact:** Demonstrated mastery of foundational ML math and statistical logic, with reproducible code and clear visualizations.
  
### Machine Learning Analysis & Model Evaluation (MIT xPro Final Assignment 20.2)
- **Notebook:** [Activity20.2_Notebook.ipynb](https://github.com/MacAries1/Required_Final_Assignment_20.1-Introduction_to_Machine_Learning_and_Advanced_Probability_starter/blob/main/Activity20.2_notebook.ipynb)
- **Focus:** Applied machine learning techniques including classification, model tuning, and performance evaluation.
- **Highlights:**
  - Explored multiple ML models (e.g., logistic regression, decision trees, random forests)
  - Evaluated models using confusion matrices, ROC curves, and precision-recall metrics
  - Tuned hyperparameters and interpreted feature importance
  - Compared model performance across different scenarios and datasets
- **Impact:** Demonstrated a full ML workflow with reproducible code, clear visualizations, and thoughtful analysis.
